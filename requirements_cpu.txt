llama-cpp-python==0.2.74
llama-cpp-python[server]==0.2.74
auto-gptq==0.4.2
exllamav2==0.0.20
ctransformers==0.2.27

-f https://download.pytorch.org/whl/torch_stable.html
torch==2.2.0+cpu
torchaudio==2.2.0+cpu
torchvision==0.17.0+cpu